# Analysis of Introgression with Chromosome-Length Alignments

A tutorial on the analysis of hybridization and introgression with whole-chromosome alignments

## Summary

Phylogenetic approaches based on sequence alignments from across the genome can serve as a useful complement to SNP-based analyses for the detection of past introgression events. In contrast to SNP-based analyses such as the ABBA-BABA test, the use of sequence alignments permits the inference of local phylogenies when more than four species are included in the dataset. Importantly, introgression tests based on such sets of phylogenies could be robust to conditions that may produce misleading results in the ABBA-BABA test. In particular, the ABBA-BABA test assumes identical substitution rates for all species and the absence of homoplasies so that derived sites can only be shared if they had the same origin; independent substitutions at the same site are ignored. These conditions assumed by the ABBA-BABA test are likely to hold in sets of recently diverged species, but may be problematic when more divergent species are compared. Phylogenetic approaches based on sequence alignments can therefore serve to verify or reject patterns of introgression determined with SNP-based methods.

On the other hand, the identification of suitable alignment blocks for phylogenetic inference across the genome can be difficult, for example when chromosome-length alignments were generated by read mapping to a distantly related reference species, a process that may result in a large proportion of missing data. One way to compensate for missing data is the use of sufficiently long alignment blocks for phylogenetic analyses, given that there is usually no shortage in overall sequence data in genomic studies. However, the use of long alignment blocks can also be problematic because the probability of within-block recombination, which violates the assumptions of most phylogenetic approaches, increases with the length of the alignment block. To account for this, methods can be applied to identify recombination breakpoints and to filter the alignment blocks accordingly. The accuracy of these methods, however, so far remains questionable, and the consequences of undetected recombination have not been tested thoroughly. Despite these potential caveats, a growing number of phylogenomic studies (e.g. [Gante et al. 2016](https://onlinelibrary.wiley.com/doi/abs/10.1111/mec.13767), [Li et al. 2016](https://genome.cshlp.org/content/early/2015/10/30/gr.186668.114)) uses long sequence alignments from aross the chromosome to detect introgression.


## Table of contents

* [Outline](#outline)
* [Dataset](#dataset)
* [Requirements](#requirements)
* [Genotype phasing](#phasing)
* [Preparing a chromosome-length alignment](#preparing)
* [Identifying alignment blocks for phylogenetic analysis](#blocks)
* [Inferring block phylogenies with IQ-TREE](#iqtree)
* [Analyzing asymmetry of trio topologies](#asymmetry)
* [Simulating recombination with c-genie](#cgenie)
* [Genome-wide gene-genealogy interrogation](#interrogation)


<a name="outline"></a>
## Outline

In this tutorial I am going to demonstrate how phylogenies from across the genome can be used to infer past introgression events. The alignment blocks used for phylogenetic inference will be extracted from a phased chromosome-length alignment, and they will be filtered according to their proportion of missing data and their frequency of recombination breakpoints to identify the most suitable alignment blocks for phylogenetic analysis. This analysis will then be conducted for each selected alignment block based on maximum likelihood with IQ-TREE. The resulting set of block phylogenies will then be used to determine imbalance among alternative phylogenetic topologies for each species trio, and as in the ABBA-BABA test in tutorial [Analysis of Introgression with SNP data](../analysis_of_introgression_with_snp_data/README.md), these imbalances will be visualized in the form of a heatmap. Additionally, one particular phylogenetic relationships will be analyzed in more detail by plotting differences in likelihood support for competing topological hypotheses.


<a name="dataset"></a>
## Dataset

The dataset used in this tutorial will be a chromosome-length alignment with phased sequences for the same 14 cichlid species that were already used in tutorials [Species-Tree Inference with SNP Data](../species_tree_inference_with_snp_data/README.md) and [Analysis of Introgression with SNP Data](../analysis_of_introgression_with_snp_data/README.md). As in these other tutorials, only data homologous to chromosome 5 of the tilapia (*Oreochromis niloticus*) genome assembly ([Conte et al. 2017](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-017-3723-5)) will be used to reduce the computational demand of the analyses. The phased chromosome-length alignment will be generated in the first part of this tutorial based on three different types of input: The VCF file [`NC_031969.f5.sub1.vcf.gz`](data/NC_031969.f5.sub1.vcf.gz) with phased SNP data produced in tutorial [Analysis of Introgression with SNP Data](../analysis_of_introgression_with_snp_data/README.md), the reference sequence for the chromosome from the tilapia assembly, and a set of files in BED format that specify, for each sample, where on the chromosome SNPs could have been detected if there were any of them. Further information on the origin of the genomic dataset can be found in the instructions to tutorial [Species-Tree Inference with SNP Data](../species_tree_inference_with_snp_data/README.md). Note, however, that after phasing the VCF file, the number of samples will be reduced to one per species to limit the run time of the analyses. As in tutorial [Divergence-Time Estimation with SNP Data](../divergence_time_estimation_with_snp_data/README.md), the sample selected per species will be the one with the least amount of missing data. These samples are listed in the table shown below:

<center>

| Sample ID | Species ID | Species name                  | Tribe         |
|-----------|------------|-------------------------------|---------------|
| IZC5      | astbur     | *Astatotilapia burtoni*       | Haplochromini |
| AUE7      | altfas     | *Altolamprologus fasciatus*   | Lamprologini  |
| JBD6      | telvit     | *Telmatochromis vittatus*     | Lamprologini  |
| JUH9      | neobri     | *Neolamprologus brichardi*    | Lamprologini  |
| LJC9      | neocan     | *Neolamprologus cancellatus*  | Lamprologini  |
| KHA7      | neochi     | *Neolamprologus chitamwebwai* | Lamprologini  |
| IVE8      | neocra     | *Neolamprologus crassus*      | Lamprologini  |
| JWH2      | neogra     | *Neolamprologus gracilis*     | Lamprologini  |
| JWG9      | neohel     | *Neolamprologus helianthus*   | Lamprologini  |
| JWH4      | neomar     | *Neolamprologus marunguensis* | Lamprologini  |
| JWH6      | neooli     | *Neolamprologus olivaceous*   | Lamprologini  |
| ISB3      | neopul     | *Neolamprologus pulcher*      | Lamprologini  |
| ISA8      | neosav     | *Neolamprologus savoryi*      | Lamprologini  |
| KFD2      | neowal     | *Neolamprologus walteri*      | Lamprologini  |

</center>

Moreover, when converting the dataset from VCF into a sequence alignment in Nexus format, only one of the phased haplotypes for each sample will be randomly selected, so that each species is then represented only by a single phased chromosome-length sequence.


<a name="requirements"></a>
## Requirements

* **bcftools:** [bcftools](http://www.htslib.org/doc/bcftools.html) ([Li 2011](https://academic.oup.com/bioinformatics/article/27/21/2987/217423)) is a fast and versatile tool for the manipulation and filtering of variant data in VCF format. Downloads and instructions for installation on Mac OS X and Linux are available at the [HTSlib download webpage](http://www.htslib.org/download/). Installation on Windows is apparently not possible.

* **AliView:** To visualize sequence alignments, the software [AliView](http://www.ormbunkar.se/aliview/) ([Larsson 2014](https://academic.oup.com/bioinformatics/article/30/22/3276/2391211)) is recommended. The installation of AliView is described at [http://www.ormbunkar.se/aliview/](http://www.ormbunkar.se/aliview/) and should be possible on all operating systems.

* **PAUP\* (command-line version):** Unlike in tutorials [Substitution Model Selection](../substitution_model_selection/README.md) and [Species-Tree Inference with SNP Data](../species_tree_inference_with_snp_data/README.md), the command-line version of PAUP* will be required for this tutorial. Precompiled binaries of these versions are available for Mac OS X, Linux, and Windwows from the [PAUP\* website]([http://phylosolutions.com/paup-test/](http://phylosolutions.com/paup-test/)). Download the correct version for your system and place it somewhere on your computer where your system can find it (i.e. in a directory that is included in your [PATH](https://en.wikipedia.org/wiki/PATH_(variable))).

* **IQ-TREE:** Precompiled binaries for Mac OS X, Linux, and Windows are available on [http://www.iqtree.org/#download](http://www.iqtree.org/#download). To install IQ-TREE on any of these systems, download the version for your operating system, and decompress this file on your machine if necessary. In the decompressed directory, you'll find a subdirectory named `bin` and inside of this subdirectory should be a file named `iqtree` or `iqtree.exe`. To easily access this executable from the command line, also place it in a directory that is included in your [PATH](https://en.wikipedia.org/wiki/PATH_(variable))).

* **FigTree:** The program [FigTree](http://tree.bio.ed.ac.uk/software/figtree/) by Andrew Rambaut is a very intuitive and useful tool for the visualization and (to a limited extent) manipulation of phylogenies encoded in [Newick](http://evolution.genetics.washington.edu/phylip/newicktree.html) format. Executables for Mac OS X, Linux, and Windows are provided on [https://github.com/rambaut/figtree/releases](https://github.com/rambaut/figtree/releases).

* **msprime:** The Python library [msprime](https://msprime.readthedocs.io/en/stable/index.html) [(Kelleher et al. 2016)](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004842) will be required for simulations of recombination. The library can be installed with pip for Python 3, using the following command:

		python3 -m pip install --user msprime
		
	The installation can be tested with these commands:
	
		python3 -c 'import msprime'


<a name="phasing"></a>
## Genotype phasing

When sequences used for phylogenetic inference of diploid organisms include heterozygous sites, inference methods like IQ-TREE usually interpret those sites as being ambiguous for two nucleotides, which means that available information (namely that both nucleotides are in fact present) is not used in the analysis. Ignoring this information could lead to shorter inferred branches for highly heterozygous samples and thus potentially to unreliable phylogenetic estimates. A better alternative is thus to "phase" heterozygous sequences before the phylogenetic analysis, and thus, to replace the single sequence per sample that may contain heterozygous sites with two sequences representing the two haplotypes of the diploid sample. In the absence of long sequencing reads such as those generated on the PacBio platform, any attempt at phasing will most likely not succeed in correctly determining both haplotypes across the entire chromosome. Nevertheless, one could expect that at least within the short regions of the genome that are used for individual phylogenetic analyses, the phasing may be correct. And even if only one of the two sequences per sample are ultimately used for the phylogenetic inference (as will be the case here), phasing will increase the amount of information available for the analysis. Because phasing is more reliable with more samples, we are going to perform phasing before, not after, reducing the dataset to one sample per species.

The two programs [BEAGLE](https://faculty.washington.edu/browning/beagle/beagle.html) ([Browning and Browning 2007](https://www.cell.com/ajhg/fulltext/S0002-9297(07)63882-8)) and [SHAPEIT](https://mathgen.stats.ox.ac.uk/genetics_software/shapeit/shapeit.html) ([Delaneau et al. 2012](https://www.nature.com/articles/nmeth.1785)) both allow rapid phasing. From my experience, the performance of both tools is very comparable. BEAGLE, however, has the advantage that it requires no conversion from VCF format into other formats; therefore, we are here going to use BEAGLE.

* Download the Java jar file of the latest version of BEAGLE from the [BEAGLE webpage](https://faculty.washington.edu/browning/beagle/beagle.html), either using a browser or the following command:

		wget https://faculty.washington.edu/browning/beagle/beagle.28Sep18.793.jar

* Have a look at the available options for BEAGLE, which you should see when you start the program without any input, as with the following command:

		java -jar beagle.28Sep18.793.jar

* Almost all of the default settings of BEAGLE are fine for our analysis. We could, however, set the population size estimate used for phasing to a value comparable to the estimate obtained in tutorial [Divergence-Time Estimation with SNP Data](../divergence_time_estimation_with_snp_data/README.md). As this estimate was on the order of 100,000, we'll specify `ne=100000`. According to the [BEAGLE manual](https://faculty.washington.edu/browning/beagle/beagle_5.0_07Sep18.pdf), specifying a correct population size is mainly important when phasing very inbred populations, so this setting is probably not very important in our case. More importantly, make sure to specify that BEAGLE should run on a single CPU with `nthreads=1`. Without this option, BEAGLE will use all CPUs available, which reduces the run time but leads to higher memory requirements that may exceed the available memory on your machine. To run phasing with BEAGLE using a single CPU and up to 4 Gb of memory, run the following command:

		java -jar -Xmx4G beagle.28Sep18.793.jar nthreads=1 ne=100000 gt="NC_031969.f5.sub1.vcf.gz" out="NC_031969.f5.sub1.phased"

	This analysis should take around 7 minutes.

* Have a look at the output file [`NC_031969.f5.sub1.phased.vcf.gz`](res/NC_031969.f5.sub1.phased.vcf.gz) written by BEAGLE, for example with `zless -S` using the following command:

		zless -S NC_031969.f5.sub1.phased.vcf.gz

	You should note that the genotypes are now separated with the pipe symbol "|" instead of the forward slash "/", and that a distinction is now being made between heterozygous genotypes such as "0|1" and "1|0". With unphased data, the lower number was always listed first as in "0/1" because their order did not have a meaning, but after phasing, all alleles before the pipe symbol are considered to form one haplotype while those after the pipe symbol form the other. **Question 1:** Do you also notice something that is unexpected? [(see answer)](#q1)

* Given that we did not run BEAGLE with a reference set of haplotypes, we should probably consider the imputed alleles as being potentially incorrect and misleading for phylogenetic analyses. Thus, it might be safer to undo the imputation before using the dataset for phylogenetic analyses. We can do so by comparing the unphased VCF file [`NC_031969.f5.sub1.vcf.gz`](data/NC_031969.f5.sub1.vcf.gz) with the phased VCF file [`NC_031969.f5.sub1.phased.vcf.gz`](res/NC_031969.f5.sub1.phased.vcf.gz) and by setting all genotypes in the phased VCF file to missing (coded by ".|.") if they were also missing in the unphased VCF file. This can be done with the Ruby script [`mask_imputed_gts.rb`](src/mask_imputed_gts.rb). The script expects as input both the unphased and phased VCF files without their headers; thus, we'll first generate versions of the two files with their headers removed. We can do so with the following commands:

		gunzip -c NC_031969.f5.sub1.vcf.gz | grep -v "#" > original.vcf
		gunzip -c NC_031969.f5.sub1.phased.vcf.gz | grep -v "#" > phased.vcf

* Then, run the script [`mask_imputed_gts.rb`](src/mask_imputed_gts.rb) with the names of the two files generated in the last step as input, followed by the name of a new file, `masked.vcf`, to which the output of the script will be written:

		ruby mask_imputed_gts.rb original.vcf phased.vcf masked.vcf

* Have a look at file `masked.vcf`, for example with using `less -S` as in the following command:

		less -S masked.vcf

	You should see that this file does contain the phased genotypes marked by the pipe ("|") symbol separating the two alleles, but that it also includes missing data just like the unphased file `NC_031969.f5.sub1.vcf.gz` did.
	
* Finally, because the file `masked.vcf` does not contain a header, we will generate a new file containing only the header of the unphased file `NC_031969.f5.sub1.vcf.gz`, and we will combine this file containing only the header with the header-less file `masked.vcf` into a new file. We will also compress the new file at the same time and name it `NC_031969.f5.sub1.phased.masked.vcf.gz`. To do so, use the following two commands:

		gunzip -c NC_031969.f5.sub1.vcf.gz | grep "#" > header.vcf
		cat header.vcf masked.vcf | gzip > NC_031969.f5.sub1.phased.masked.vcf.gz
		
* Before continuing with the next section of the tutorial, you might want to remove some of the larger files generated in the last couple of steps that we will not need anymore. To do so, use the following command:
		
		rm original.vcf header.vcf phased.vcf masked.vcf


<a name="preparing"></a>
## Preparing a chromosome-length alignment

In this part of the tutorial, we are going to prepare a single chromosome-length alignment, including one phased sequence for each of the 14 cichlid species included in the dataset. We are going to need three different sources of information:

1.	The VCF file [`NC_031969.f5.sub1.phased.masked.vcf.gz`](res/NC_031969.f5.sub1.phased.masked.vcf.gz) with phased SNP variation generated in tutorial [Analysis of Introgression with SNP Data](../analysis_of_introgression_with_snp_data/README.md).

2. As the VCF file `NC_031969.f5.sub1.phased.masked.vcf.gz` does not contain information about invariant sites but these are required for phylogenetic inference with IQ-TREE, we assume that the sites between those included in the VCF file are in fact unchanged between the species in the dataset and the tilapia reference sequence. Thus, we'll use the reference sequence for chromosome 5 of tilapia to fill the gaps between SNPs included in the VCF. 		
3. The assumption that sites between SNPs are invariant is only justified for sites in which SNPs could have been called at all if there had been any. This is not the case for all of the sites between the SNPs, due to low sequencing coverage in some regions or low mapping quality in repetitive regions. It would also have been impossible to call SNPs very close to indel variation, because these were filtered when the original VCF file `NC_031969.f5.sub1.vcf.gz` (see tutorial [Species-Tree Inference with SNP Data](../species_tree_inference_with_snp_data/README.md)) was prepared. Thus, we will take into account information about the chromosomal regions in which SNP variation could not have been called in the first place, and we will conservatively set these chromosomal regions to missing, coded by "N", in the generated alignment. The information about callable chromosomal regions is contained in a set of files in [BED format](http://genome.ucsc.edu/FAQ/FAQformat#format1); these files are within a compressed directory named [`masks.tgz`](data/masks.tgz).

* Obtain all required input files and place them in your analysis directory. To download the sequence for chromosome 5 of tilapia from GenBank, you can use the following command:

		wget 'http://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?tool=portal&sendto=on&log$=seqview&db=nuccore&dopt=fasta&val=NC_031969.1&extrafeat=0&maxplex=1' -O NC_031969.fasta
		
	The downloaded sequence will in in Fasta format in a file named `NC_031969.fasta`.

* Unless the directory with the files in BED format has already been uncompressed automatically, do so with the following command:

		tar -xzf masks.tgz
		
* Have a look at the content of one of the files in BED format, for example using the following command:

		less masks/AUE7.NC_031969.f5.merged.bed
		
	You'll see that these files contain three columns, as shown in the text below:
	
		NC_031969       0       45144
		NC_031969       45169   88297
		NC_031969       88299   88363
		NC_031969       88365   88370
		NC_031969       88372   98367
		NC_031969       98368   98403
		NC_031969       98405   98409
		NC_031969       98411   98429
		NC_031969       98431   100023
		...
		
	The second and third of these columns indicate the beginning and the end of chromosomal regions that were masked because SNPs in these regions would not have been detected due to low coverage or other reasons. You'll see that these uncallable regions are quite long compared to the callable regions in between them. In the example shown above, only few callable sites were found within the first 100 kbp of the chromosome. Overall, about two thirds of the chromosome are uncallable, which can be explained by a combination of several causes, including mapping to a distant reference, masking of repetitive regions, and rigorous filtering of sites close to insertions and deletions. However, even after conservatively setting all these regions to missing, the remaining sequence information will be sufficient for phylogenetic analysis.

* The three different types of information (the SNP data, the reference sequence, and the information on uncallable regions) will be combined to generate chromosome-length sequences in Fasta format by the Ruby script [`fill_seq.rb`](src/fill_seq.rb). To reduce the memory requirement of this script, we are going to run it separately for each of the samples included in the dataset, and as input for the script we are going to use individual VCF files that contain SNP data only for the respective sample. Prepare these individual VCF files from the full VCF file [`NC_031969.f5.sub1.phased.masked.vcf.gz`](data/NC_031969.f5.sub1.phased.masked.vcf.gz), using the following command (if you copied the VCF file from the analysis directory of tutorial [Analysis of Introgression with SNP Data](../analysis_of_introgression_with_snp_data/README.md), it might be uncompressed; if so, just remove the file extension `.gz` in this command):

		for i in IZC5 AUE7 JBD6 JUH9 LJC9 KHA7 IVE8 JWH2 JWG9 JWH4 JWH6 ISB3 ISA8 KFD2
		do
			bcftools view -s ${i} -o ${i}.NC_031969.f5.masked.vcf NC_031969.f5.sub1.phased.masked.vcf.gz
		done
		
	The above command should have written 14 separate uncompressed VCF files. To make sure that these have been generated, you could use `ls *.NC_031969.f5.masked.vcf`.

* We can now run the script [`fill_seq.rb`](src/fill_seq.rb) to combine, for each sample, the SNP data with the reference sequence and the information on callable regions, using the following command:

		for i in *.NC_031969.f5.masked.vcf
		do
			sample_id=`basename ${i%.NC_031969.f5.masked.vcf}`
			echo -n "Translating file ${i}..."
			ruby fill_seq.rb ${i} NC_031969.fasta masks/${sample_id}.NC_031969.f5.merged.bed ${sample_id}.NC_031969.f5.masked.fasta 1
			echo " done."
		done

	 This should take about ten minutes to finish. As you can see from the command above, the script `fill_seq.rb` expects five command-line arguments. These are, in this order,
	
	* the VCF file with SNP information,
	* the reference sequence in Fasta format,
	* the file in BED format containing information about callable regions,
	* the name of an output file, which will be written in Fasta format.
	* a flag specifying whether only the first, the second, or both phased haplotypes should be written to the output. Here, we arbitrarily chose the first haplotype.

	The script expects that all input files are for a single chromosome only, so we would have to run it multiple times if we would use information from several chromosomes.

* Have a look at one of the Fasta files generated by script `fill_seq.rb`, for example using the following command:

		less -S AUE7.NC_031969.f5.masked.fasta
		
	You'll see that it contains a single sequence, the first haplotype of the phased VCF file.

* Next, combine all sequences into a single file in Fasta format named `NC_031969.f5.masked.fasta`. Because all sequences are already aligned in the same way to the tilapia reference sequence, the combined file will already be perfectly aligned and no realignment with a tool like MAFFT (see tutorial [Multiple Sequence Alignment](../multiple_sequence_alignment/README.md)) will be necessary. The combined Fasta file `NC_031969.f5.masked.fasta` will have a file size of about 500 MB. To combine the sequences, execute the following command:

		cat *.NC_031969.f5.masked.fasta > NC_031969.f5.masked.fasta
		
* You could now remove the per-sample Fasta and VCF files to save disk space, using the following commands:

		rm *.NC_031969.f5.masked.fasta
		rm *.NC_031969.f5.masked.vcf


<a name="blocks"></a>
## Identifying alignment blocks for phylogenetic analysis

After having generated a chromosome-length alignment, we can now apply a sliding-window approach to identify blocks of the alignment that are suitable for phylogenetic analysis. Ideally, the blocks used for phylogenetic analysis should have as little missing data as possible, be as informative as possible, and show no signs of within-block recombination. Thus, we are going to filter alignment blocks based on informativeness and signals of recombination after extracting them from the chromosome-length alignment, and the extraction itself will exclude blocks with a high proportion of missing data.

As the length of each block, we here use 5 kbp, assuming that this length is a good compromise between increasing probability of undetected recombination with longer blocks and decreasing phylogenetic signal with shorter blocks. For a more thorough analysis, however, it might be worth testing this assumption with different block sizes.

* To extract alignment blocks from the chromosome-length alignment, we can use the Ruby script [`extract_blocks.rb`](src/extract_blocks.rb). This script expects four command-line arguments; these are
	* the name of the chromosome-length alignment in Fasta format,
	* the name of a new directory to which all block-alignment files will be written in Nexus format,
	* the size of the alignment blocks,
	* (optionally) a maximum proportion of missing data allowed in alignment blocks.

	Thus, to name the output directory `blocks`, use a block size 5,000 bp, and allow maximally half of the block alignment to consist of missing data, run the script with the following command:
	
		ruby extract_blocks.rb NC_031969.f5.masked.fasta blocks 5000 0.5
		
	**Question 2:** How many alignment blocks were written and how many were removed due to a high proportion of missing data? [(see answer)](#q2)
	
* Have a look at the new directory named `blocks`. Note that the files in this directory are named according to the name of the linkage group and the first and the last position of the alignment block:

		NC_031969.f5.masked_02505001_02509999.nex
		NC_031969.f5.masked_04865001_04869999.nex
		NC_031969.f5.masked_04910001_04914999.nex
		NC_031969.f5.masked_04925001_04929999.nex
		NC_031969.f5.masked_04935001_04939999.nex
		NC_031969.f5.masked_05010001_05014999.nex
		NC_031969.f5.masked_05030001_05034999.nex
		...

* To facilitate the phylogenetic analyses, it will help to simplify the alignment names with the following set of commands.

		for i in blocks/*.nex
		do
			new_name=`echo ${i} | sed 's/\.f5\.masked//g'`
			mv ${i} ${new_name}
		done

* The files in directory `blocks` should now be named like this:

		NC_031969_02505001_02509999.nex
		NC_031969_04865001_04869999.nex
		NC_031969_04910001_04914999.nex
		NC_031969_04925001_04929999.nex
		NC_031969_04935001_04939999.nex
		NC_031969_05010001_05014999.nex
		NC_031969_05030001_05034999.nex
		...

* Pick one of the files in this directory at random, and open it either in a text editor or in AliView just to get a feeling for the size of the alignment block, as well as for its sequence variation and the amount of missing data. You should see something like this:<p align="center"><img src="img/aliview1.png" alt="AliView" width="600"></p> Like the alignment shown above, many alignments still contain quite a proportion of missing data due to the strict filtering based on coverage, mapping quality, and indel proximity.

* To filter the alignment blocks by phylogenetic informativeness, we are going to quantify their numbers of parsimony-informative sites. These are the sites at which at least two sequences share a derived site, so that their grouping is supported by this site. In other words, parsimony-informative sites result only from subsitutions on internal branches of the phylogeny, not from those that occur on terminal branches. The Ruby script [`get_number_of_pi_sites.rb`](src/get_number_of_pi_sites.rb) allows the quick calculation of this number from an alignment in Nexus format. Run this script with the following command to quantify the numbers of parsimony-informative sites in all alignment blocks:

		for i in blocks/*.nex
		do
			ruby get_number_of_pi_sites.rb ${i}
		done

	This should show that most alignments contain between 10 and 30 parsimony-informative sites. Particularly those with 10 or less such sites will not be informative enough to fully resolve the phylogeny of the 14 species in the dataset, because even if every internal branch would be supported by only a single substitution, this would require 11 parsimony-informative sites.

* Before applying a threshold on the number of parsimony-informative sites, we are going to quantify the number of so-called hemiplasies in each alignment block as a second criterion for filtering. Simply put, a hemiplasy is a site that supports a grouping that is in conflict with a grouping supported by another site of the same alignment. Possible explanations for hemiplasy include sequencing errors but within-alignment recombination in combination with incomplete lineage sorting can also produce them. And because within-alignment recombination can lead to unreliable phylogenetic inference, this means that alignments with none of few hemiplasies are more suitable for phylogenetic inference than other alignments with many hemiplasies ([Maynard Smith and Smith, 1998](https://academic.oup.com/mbe/article/15/5/590/987861)).

	Fortunately, the number of hemiplasies can easily be approximated as the difference between the number of variable sites and the so-called parsimony score of an alignment, which is the lowest number of substitutions on a phylogeny that is required to produce the alignment (the result is only an approximation because some hemiplasies may increase the parsimony-score by more than 1 if three or more substitutions are required to explain them). To calculate the number of variable sites, the script [`get_number_of_variable_sites.rb`](src/get_number_of_variable_sites.rb) can be used. Before moving on to calculate parsimony scores, first apply this script alone to get a feeling of the number of variable sites in the alignments:
	
		for i in blocks/*.nex
		do
			ruby get_number_of_variable_sites.rb ${i}
		done

	You should see that most alignments have around 40-70 variable sites, but some particularly variable alignments have over 100.

* The calculation of parsimony scores requires that the software PAUP* is installed on the command line, which can be checked with `paup -V`. If PAUP* seems to be working, the BASH script [`get_parsimony_score.sh`](src/get_parsimony_score.sh) can be used to obtain the parsimony score of a Nexus-format alignment. This script performs several steps: It writes a command file for PAUP* which specifies the task that PAUP* should perform as well as the input file, then it runs PAUP* with this command file, it reads the output of PAUP* to extract the parsimony score, and finally, it removes the temporary files that were written by PAUP* to clean up the directory. To see whether this process works well, run script [`get_parsimony_score.sh`](src/get_parsimony_score.sh) with a randomly selected alignment file as in the following command:

		bash get_parsimony_score.sh blocks/NC_031969_08400001_08404999.nex
		
	With this alignment, the parsimony score is 115.
	
* Now, let's combine the different scripts to quantify the parsimony-score and the number of hemiplasies for all alignments, and to record this information in a table. The following block of code will allow this, writing the result to a new file named `block_stats.txt`:

		echo -e "id\tn_pi_sites\tn_hemiplasies" > block_stats.txt
		for i in blocks/*.nex
		do
			id=`basename ${i%.nex}`
			n_pi_sites=`ruby get_number_of_pi_sites.rb ${i}`
			n_variable_sites=`ruby get_number_of_variable_sites.rb ${i}`
			parsimony_score=`bash get_parsimony_score.sh ${i}`
			n_hemiplasies=$((${parsimony_score}-${n_variable_sites}))
			echo -e "${id}\t${n_pi_sites}\t${n_hemiplasies}"
		done >> block_stats.txt

* Have a look at the content of file [`block_stats.txt`](res/block_stats.txt). The first part of the content should be the following, where the number of parsimony-informative sites is written in the second column and the third column contains the (approximated) number of hemiplasies:

		id	n_pi_sites	n_hemiplasies
		NC_031969_02505001_02509999	13	2
		NC_031969_04865001_04869999	6	3
		NC_031969_04910001_04914999	8	6
		NC_031969_04925001_04929999	13	11
		NC_031969_04935001_04939999	5	2
		NC_031969_05010001_05014999	6	1
		NC_031969_05030001_05034999	8	2
		NC_031969_05040001_05044999	9	3
		NC_031969_05065001_05069999	15	11
		NC_031969_05185001_05189999	12	9
		NC_031969_05220001_05224999	19	16
		NC_031969_05230001_05234999	14	7
		NC_031969_05255001_05259999	5	1
		NC_031969_05915001_05919999	44	39
		NC_031969_05920001_05924999	36	37
		...

	It appears that the two values are closely correlated: the more parsimony-informative sites an alignment has the more hemiplasies is contains. This is in part expected because without parsimony-informative sites there could be no hemiplasies. It means, however, that a compromise will need to be made between too little information and too many hemiplasies, indicating within-alignment recombination.
	
* To allow us to decide on appropriate thresholds for the numbers of parsimony-informative sites and hemiplasies, let's plot the two values. In the R environment, you could use the following commands to do so (just type `R` to enter the R environment from the command line):

		table <- read.table("block_stats.txt", header=T)
		pdf("block_stats.pdf", height=7, width=7)
		plot(table$n_pi_sites, table$n_hemiplasies, xlim=c(0,70), ylim=c(0,70), xlab="Parsimony-informative sites", ylab="Hemiplasies")
		abline(a=0, b=1)
		dev.off()

	(to quit the R environment, type `quit(save="no")`). This should produce the plot shown below, written to file [`block_stats.pdf`](res/block_stats.pdf), where the black line indicates the diagonal:<p align="center"><img src="img/block_stats.png" alt="Block stats" width="600"></p> The fact that some points lie above the diagonal means the these alignments have more hemiplasies than parsimony-informative sites, which can only be explained by site patterns that require more than three changes on even the most parsimonious phylogeny. These results suggest that none of the alignments are free of recombination; therefore, the phylogenies that will be inferred from these alignments may not be completely reliable. Selecting shorter alignment blocks could help to reduce within-alignment recombination; however, this would also further reduce the informativeness of the alignments, which is already low in the current alignments.
	
	Given the above plot, a reasonable choice for filtering the most suitable alignments may be to exclude those with less than 15 parsimony-informative sites, those with more than 30 hemiplasies, and those in which the difference between the numbers of parsimony-informative sites and hemiplasies is less than 5. The added lines in the plot below indicate the selected region of the block (the region to the bottom-right of the three lines):p align="center"><img src="img/block_stats_region.png" alt="Block stats" width="600"></p>
	
* Remove all block alignments that are considered unsuitable according to the thresholds for the numbers of parsimony-informative sites and hemiplasies and the threshold for the difference between these two numbers. Use the following set of commands to do so:
	
		cat block_stats.txt | tail -n +2 > tmp.txt
		while read line
		do
		    id=`echo ${line} | cut -d " " -f 1`
		    n_pi_sites=`echo ${line} | cut -d " " -f 2`
		    n_hemiplasies=`echo ${line} | cut -d " " -f 3`
			if (( ${n_pi_sites} < 15 )) || (( ${n_hemiplasies} > 30 )) || (( ${n_pi_sites} < ${n_hemiplasies} + 5 ))
			then
				echo "Removing file blocks/${id}.nex"
				rm blocks/${id}.nex
			fi
		done < tmp.txt
		rm tmp.txt

	**Question 3:** How many block alignments remain in the `blocks` directory after applying these thresholds? [(see answer)](#q3)

<a name="iqtree"></a>
##Inferring block phylogenies with IQ-TREE

In this part of the tutorial, we are going to infer phylogenies for each remaining alignment block; the set of inferred phylogenies will subsequently be used to determine asymmetries in the topologies of species trios which can serve as an indicator for introgression. Note that it may in fact be important for this subsequent test that the set of phylogenies is generated based on maximum likelihood, without assuming a clock model as in BEAST analyses. While this should probably be tested in more detail, I found in preliminary analyses that clock-rate variation among species may influence the frequencies of species-trio topologies in time-calibrated analyses, but that it has no or only weak effect on maximum-likelihood inference without a clock model. As a result, I also do not recommend any longer to use the related approach of [Meyer et al. (2017)](https://academic.oup.com/sysbio/article/66/4/531/2670093).
